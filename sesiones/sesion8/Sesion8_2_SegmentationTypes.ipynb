{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pQg9dlnMTBBz",
        "Vwmw-nAQHflx"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<image src=\"https://i.imgur.com/HrRxc5o.jpeg\" width=100%>"
      ],
      "metadata": {
        "id": "ascs3JAY98Es"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existen tres tipos principales de segmentación en visión por computadora: **segmentación semántica**, **segmentación por instancia** y **segmentación panóptica**. La segmentación semántica clasifica cada píxel de una imagen según su categoría (por ejemplo, “árbol” o “carretera”), sin distinguir entre diferentes objetos individuales de la misma clase. La segmentación por instancia identifica objetos individuales dentro de una misma categoría, como distinguir entre varios “autos” en una escena. Finalmente, la segmentación panóptica combina ambos enfoques, asignando a cada píxel una etiqueta semántica y, cuando corresponde, una instancia única del objeto."
      ],
      "metadata": {
        "id": "rU3cqLn1chr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<image src=\"https://i.imgur.com/8vukGi4.jpeg\" width=85%>"
      ],
      "metadata": {
        "id": "7WcpFZaq2uog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<image src=\"https://i.imgur.com/1RLt9az.jpeg\" width=85%>"
      ],
      "metadata": {
        "id": "4_p9vo7c2kvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<image src=\"https://i.imgur.com/YaTrlkl.jpeg\" width=85%>"
      ],
      "metadata": {
        "id": "3QJELX3g223K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#00FFFF'>**Diferentes tipos de Segmentación 👀**</font>"
      ],
      "metadata": {
        "id": "az9ds02E_VUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importamos librerías y dependencias**"
      ],
      "metadata": {
        "id": "pQg9dlnMTBBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/segment-anything.git' --q\n",
        "!pip install jupyter_bbox_widget roboflow dataclasses-json supervision==0.23.0 --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbTKC78dPWw0",
        "outputId": "805f6427-d2be-49dc-9e21-e358bdeddec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.5/151.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.5/765.5 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krISn4GqzX10",
        "outputId": "0c69679c-636c-4548-da98-720c4d21f0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import cv2\n",
        "import random\n",
        "import json\n",
        "import supervision as sv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation"
      ],
      "metadata": {
        "id": "58sA0c-gnfEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#00FFFF'> **1. Segmentación panóptica** </font>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SpMckTZzgcg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Descargamos y configuramos SAM pre-entrenado listo para usarse**"
      ],
      "metadata": {
        "id": "CE-wZDsVRyZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#No modifiques esta sección"
      ],
      "metadata": {
        "id": "RDHm4kReWNaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/weights\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P /content//weights"
      ],
      "metadata": {
        "id": "Nwx9LFSuP3DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = os.path.join(\"/content\", \"weights\", \"sam_vit_h_4b8939.pth\")\n",
        "print(checkpoint, \"; exist:\", os.path.isfile(checkpoint))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0cxWvIjQBbR",
        "outputId": "2876c2fe-472e-4cac-86b2-6ca450942b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/weights/sam_vit_h_4b8939.pth ; exist: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = \"vit_h\"\n",
        "\n",
        "sam = sam_model_registry[None](checkpoint=checkpoint).to(device=None)"
      ],
      "metadata": {
        "id": "-PN0_KW2AbOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sube cualquier imagen o imágenes aquí para trabajar**"
      ],
      "metadata": {
        "id": "YhRFoYINR68i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "image_paths = []\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  if not os.path.exists('uploaded_images'):\n",
        "    os.makedirs('uploaded_images')\n",
        "\n",
        "  path = os.path.join('uploaded_images', fn)\n",
        "  image_paths.append(path)\n",
        "\n",
        "  with open(path, 'wb') as f:\n",
        "    f.write(uploaded[fn])\n",
        "\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes and saved to {path}'.format(\n",
        "      name=fn, length=len(uploaded[fn]), path=path))\n",
        "\n",
        "# Guardamos los paths de cada image en image_path, descomenta la línea de abajo para verlos\n",
        "#print(\"Saved image paths:\", image_paths)"
      ],
      "metadata": {
        "id": "PZnBeDoJiti3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# La posición del path depende del orden de subida de las imagenes a trabajar, si deseas cambiar la imagen,\n",
        "# modifica el índice de la lista al path de la imagen a usar, no olvidar que los índices empiezan hasta 0\n",
        "# y van hasta n-1 donde n es el número de imágenes\n",
        "\n",
        "image_path = image_paths[0]\n",
        "src_image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(None, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image_rgb)\n",
        "plt.title('Source Image')\n",
        "plt.show() #Visualización de la imagen seleccionada"
      ],
      "metadata": {
        "id": "PzTRLu6vioy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creación de máscaras y visualización de Segmentación Panóptica**"
      ],
      "metadata": {
        "id": "b38RrgOncm3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear las máscaras usando SAM a partir de la imagen RGB\n",
        "\n",
        "mask_generator = SamAutomaticMaskGenerator(None)\n",
        "src_image = cv2.imread(None)\n",
        "image_rgb = cv2.None(src_image, cv2.COLOR_BGR2RGB)\n",
        "sam_result = mask_generator.generate(None)"
      ],
      "metadata": {
        "id": "Pt6knNkigj-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "detections = sv.Detections.from_sam(sam_result=None)\n",
        "annotated_image = mask_annotator.annotate(scene=src_image.copy(), detections=detections)\n",
        "\n",
        "#Visualización de las imágenes\n",
        "sv.plot_images_grid(\n",
        "    images=[None, None],\n",
        "    grid_size=(1, 2),\n",
        "    titles=['Source Image', 'Panoptic segmentation']\n",
        ")"
      ],
      "metadata": {
        "id": "pA5BXn6rglD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualización de máscaras de segmentación generadas por SAM**"
      ],
      "metadata": {
        "id": "oPwnXPIXdM6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "masks = [\n",
        "    mask['segmentation']\n",
        "    for None\n",
        "    in sorted(sam_result, key=lambda x: x['area'], reverse=True)\n",
        "]\n",
        "\n",
        "num_rows = (len(masks) + 7) // 8\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=None,\n",
        "    grid_size=(8, num_rows),\n",
        "    size=(16, 16)\n",
        ")"
      ],
      "metadata": {
        "id": "4QdD_YvagnDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#00FFFF'> **2. Segmentación semántica** </font>"
      ],
      "metadata": {
        "id": "DpxLrpBDzgCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Descargamos Mask2Former desde HuggingFace**"
      ],
      "metadata": {
        "id": "Vwmw-nAQHflx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#No modifiques esta sección"
      ],
      "metadata": {
        "id": "elGMQeHjZrKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-base-coco-panoptic\")\n",
        "model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-base-coco-panoptic\")"
      ],
      "metadata": {
        "id": "WGxIE9sNgtwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Algunos labels del pre-entreno para buscar imágenes relacionadas a estos\n",
        "\n",
        "config = model.config\n",
        "id2label = config.id2label\n",
        "\n",
        "for id, label in list(id2label.items())[:10]:\n",
        "  print(f\"ID: {id}, Label: {label}\")"
      ],
      "metadata": {
        "id": "VdgnM26YgsVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sube cualquier imagen o imágenes aquí para trabajar**"
      ],
      "metadata": {
        "id": "wlPhtVp91Yux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "image_paths = []\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  if not os.path.exists('uploaded_images'):\n",
        "    os.makedirs('uploaded_images')\n",
        "\n",
        "  path = os.path.join('uploaded_images', fn)\n",
        "  image_paths.append(path)\n",
        "\n",
        "  with open(path, 'wb') as f:\n",
        "    f.write(uploaded[fn])\n",
        "\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes and saved to {path}'.format(\n",
        "      name=fn, length=len(uploaded[fn]), path=path))\n",
        "\n",
        "# Guardamos los paths de cada image en image_path, descomenta la línea de abajo para verlos\n",
        "#print(\"Saved image paths:\", image_paths)"
      ],
      "metadata": {
        "id": "ybwz7N-kgvWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# La posición del path depende del orden de subida de las imagenes a trabajar, si deseas cambiar la imagen,\n",
        "# modifica el índice de la lista al path de la imagen a usar, no olvidar que los índices empiezan hasta 0\n",
        "# y van hasta n-1 donde n es el número de imágenes\n",
        "\n",
        "image = image_paths[0]\n",
        "src_image = Image.open(image)\n",
        "plt.imshow(src_image)\n",
        "plt.title('Source Image')\n",
        "plt.show() #Visualización de la imagen seleccionada"
      ],
      "metadata": {
        "id": "czVfNLxWh8-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Obtenemos las máscaras de segmentación de Mask2Former**"
      ],
      "metadata": {
        "id": "urb7kLJaIy45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(images=None, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "d-aPdbVN1lU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(**None)"
      ],
      "metadata": {
        "id": "gWngDVhI2bo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_map = processor.post_process_semantic_segmentation(None, target_sizes=[None.size[::-1]])[0]\n",
        "print(predicted_map.shape)"
      ],
      "metadata": {
        "id": "xzZ6ke02ixIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_palette = [list(np.random.choice(range(256), size=3)) for _ in range(len(model.config.id2label))]\n",
        "print(color_palette)"
      ],
      "metadata": {
        "id": "DeHAKlA4iwQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualización de Segmentación Semántica**"
      ],
      "metadata": {
        "id": "Rd1-NzSaKh9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seg = None # Cambio de nombre de una variable anterior\n",
        "color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8)\n",
        "palette = np.array(color_palette)\n",
        "for label, color in enumerate(palette):\n",
        "    color_seg[seg == label, :] = color\n",
        "# Convert to BGR\n",
        "color_seg = color_seg[..., ::-1]\n",
        "\n",
        "img = np.array(None)\n",
        "color_seg_resized = cv2.resize(color_seg, (img.shape[1], img.shape[0]))\n",
        "\n",
        "# Imagen y máscara (NO modificar 🙏🏼)\n",
        "img = img * 0.5 + color_seg_resized * 0.5\n",
        "img = img.astype(np.uint8)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 8))\n",
        "\n",
        "#Visualización de las imágenes\n",
        "axes[0].imshow(None)\n",
        "axes[0].set_title('Source Image')\n",
        "axes[1].imshow(None)\n",
        "axes[1].set_title('Semantic Segmentation')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8gvVqWWli-nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#00FFFF'> **3. Segmentación de instancias** </font>"
      ],
      "metadata": {
        "id": "8EK6cY_f5evv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sube cualquier imagen o imágenes aquí para trabajar**"
      ],
      "metadata": {
        "id": "VrhbcV_OSMIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "image_paths = []\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  if not os.path.exists('uploaded_images'):\n",
        "    os.makedirs('uploaded_images')\n",
        "\n",
        "  path = os.path.join('uploaded_images', fn)\n",
        "  image_paths.append(path)\n",
        "\n",
        "  with open(path, 'wb') as f:\n",
        "    f.write(uploaded[fn])\n",
        "\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes and saved to {path}'.format(\n",
        "      name=fn, length=len(uploaded[fn]), path=path))\n",
        "\n",
        "# Guardamos los paths de cada image en image_path, descomenta la línea de abajo para verlos\n",
        "#print(\"Saved image paths:\", image_paths)"
      ],
      "metadata": {
        "id": "2LIFmZBQjCtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# La posición del path depende del orden de subida de las imagenes a trabajar, si deseas cambiar la imagen,\n",
        "# modifica el índice de la lista al path de la imagen a usar, no olvidar que los índices empiezan hasta 0\n",
        "# y van hasta n-1 donde n es el número de imágenes\n",
        "\n",
        "image = image_paths[0]\n",
        "src_image = Image.open(image)\n",
        "plt.imshow(src_image)\n",
        "plt.title('Source Image')\n",
        "plt.show() #Visualización de la imagen seleccionada"
      ],
      "metadata": {
        "id": "77oajJ0xjD4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Obtenemos las máscaras de segmentación de Mask2Former**"
      ],
      "metadata": {
        "id": "KuLV3Q3fSUQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(images=src_image, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "nsdp1_9d9Be2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "NAtN9-2x9Be3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = processor.post_process_instance_segmentation(None, target_sizes=[None.size[::-1]], threshold=0.9)[0]\n",
        "print(results.keys())"
      ],
      "metadata": {
        "id": "-SBlFTUXjFsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtención de los IDs de las máscaras para revisarlas de forma individual\n",
        "\n",
        "segment_to_label = {segment['id']: segment['label_id'] for segment in results[\"segments_info\"]}\n",
        "\n",
        "def get_available_segment_ids(results):\n",
        "\n",
        "    segmentation = results['segmentation'].numpy()\n",
        "    unique_ids = np.unique(segmentation)\n",
        "\n",
        "    available_ids = [id for id in unique_ids]\n",
        "\n",
        "    return available_ids\n",
        "\n",
        "available_ids = get_available_segment_ids(results)\n",
        "print(\"Available segment IDs:\", [id.item() for id in available_ids])"
      ],
      "metadata": {
        "id": "CHAQ4ioWjHLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización individual de máscaras\n",
        "def get_mask(segment_id):\n",
        "  if segment_id in segment_to_label:\n",
        "    print(\"Visualizing mask for:\", model.config.id2label[None[None]])\n",
        "\n",
        "    mask = (None['segmentation'].None() == None)\n",
        "    visual_mask = (mask * 255).astype(np.uint8)\n",
        "    visual_mask = Image.fromarray(visual_mask)\n",
        "\n",
        "    plt.imshow(visual_mask)\n",
        "    plt.show()\n",
        "  else:\n",
        "    print(f\"Segment ID {segment_id} not found in segment_to_label. Skipping visualization.\")\n",
        "    return None\n",
        "\n",
        "get_mask(segment_id=0)"
      ],
      "metadata": {
        "id": "dYLE23NqjIQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualización Segmentación de Instancias**"
      ],
      "metadata": {
        "id": "0y06VrW9VxzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_instance_segmentation(segmentation, segments_info):\n",
        "\n",
        "    fig, axes_arr = plt.subplots(1, 2, figsize=(10, 8)) # Create 2 subplots\n",
        "    axes_img, axes_seg = axes_arr\n",
        "\n",
        "    axes_img.imshow(None)\n",
        "    axes_img.set_title('Source Image')\n",
        "    axes_seg.imshow(None)\n",
        "    axes_seg.set_title('Instance Segmentation')\n",
        "\n",
        "    instance_colors = {}\n",
        "    for segment in None:\n",
        "        segment_id = None['id']\n",
        "        if segment_id not in instance_colors:\n",
        "            instance_colors[None] = [random.randint(0, 255) for _ in range(3)]\n",
        "\n",
        "    for segment in None:\n",
        "        segment_id = segment['id']\n",
        "        segment_label_id = segment['label_id']\n",
        "        segment_label = model.config.id2label[None]\n",
        "\n",
        "        mask = (segmentation.numpy() == None)\n",
        "\n",
        "        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for contour in contours:\n",
        "            axes_seg.plot(contour[:, 0, 0], contour[:, 0, 1], color=np.array(instance_colors[segment_id]) / 255, linewidth=0.5)\n",
        "\n",
        "        x, y = np.mean(contour, axis=0)[0]\n",
        "        axes_seg.text(x, y, segment_label, color='white', backgroundcolor=np.array(instance_colors[segment_id]) / 255, fontsize=8)\n",
        "\n",
        "    plt.show(/\n",
        "#Visualización de las imágenes\n",
        "draw_instance_segmentation(**None)"
      ],
      "metadata": {
        "id": "CpfLFtMDjKEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#00FFFF'> **Bibliografía** </font>\n",
        "\n",
        "Piotr Skalski. (Jan 22, 2024). How to Use the Segment Anything Model (SAM). Roboflow Blog: https://blog.roboflow.com/how-to-use-segment-anything-model-sam/\n",
        "\n",
        "Jacob Solawetz. (Apr 7, 2023). What is Segment Anything Model (SAM)? A Breakdown.. Roboflow Blog: https://blog.roboflow.com/segment-anything-breakdown/\n",
        "\n",
        "Rogge, N. (2025). Tutorials. Github Repository: https://github.com/NielsRogge/Transformers-Tutorials\n",
        "\n",
        "Cheng, B., Misra, I., Schwing, A. G., Kirillov, A., & Girdhar, R. (2022). Masked-attention Mask Transformer for Universal Image Segmentation. arXiv. https://arxiv.org/abs/2112.01527\n",
        "\n",
        "Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A. C., Lo, W.-Y., Dollár, P., & Girshick, R. (2023). Segment Anything. arXiv. https://arxiv.org/abs/2304.02643"
      ],
      "metadata": {
        "id": "3188tRNwY9mN"
      }
    }
  ]
}