{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pQg9dlnMTBBz",
        "Vwmw-nAQHflx"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<image src=\"https://i.imgur.com/HrRxc5o.jpeg\" width=100%>"
      ],
      "metadata": {
        "id": "ascs3JAY98Es"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existen tres tipos principales de segmentaciÃ³n en visiÃ³n por computadora: **segmentaciÃ³n semÃ¡ntica**, **segmentaciÃ³n por instancia** y **segmentaciÃ³n panÃ³ptica**. La segmentaciÃ³n semÃ¡ntica clasifica cada pÃ­xel de una imagen segÃºn su categorÃ­a (por ejemplo, â€œÃ¡rbolâ€ o â€œcarreteraâ€), sin distinguir entre diferentes objetos individuales de la misma clase. La segmentaciÃ³n por instancia identifica objetos individuales dentro de una misma categorÃ­a, como distinguir entre varios â€œautosâ€ en una escena. Finalmente, la segmentaciÃ³n panÃ³ptica combina ambos enfoques, asignando a cada pÃ­xel una etiqueta semÃ¡ntica y, cuando corresponde, una instancia Ãºnica del objeto."
      ],
      "metadata": {
        "id": "rU3cqLn1chr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<image src=\"https://i.imgur.com/8vukGi4.jpeg\" width=85%>"
      ],
      "metadata": {
        "id": "7WcpFZaq2uog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<image src=\"https://i.imgur.com/1RLt9az.jpeg\" width=85%>"
      ],
      "metadata": {
        "id": "4_p9vo7c2kvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<image src=\"https://i.imgur.com/YaTrlkl.jpeg\" width=85%>"
      ],
      "metadata": {
        "id": "3QJELX3g223K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#00FFFF'>**Diferentes tipos de SegmentaciÃ³n ğŸ‘€**</font>"
      ],
      "metadata": {
        "id": "az9ds02E_VUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importamos librerÃ­as y dependencias**"
      ],
      "metadata": {
        "id": "pQg9dlnMTBBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/segment-anything.git' --q\n",
        "!pip install jupyter_bbox_widget roboflow dataclasses-json supervision==0.23.0 --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbTKC78dPWw0",
        "outputId": "805f6427-d2be-49dc-9e21-e358bdeddec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m151.5/151.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m765.5/765.5 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krISn4GqzX10",
        "outputId": "0c69679c-636c-4548-da98-720c4d21f0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import cv2\n",
        "import random\n",
        "import json\n",
        "import supervision as sv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation"
      ],
      "metadata": {
        "id": "58sA0c-gnfEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#00FFFF'> **1. SegmentaciÃ³n panÃ³ptica** </font>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SpMckTZzgcg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Descargamos y configuramos SAM pre-entrenado listo para usarse**"
      ],
      "metadata": {
        "id": "CE-wZDsVRyZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#No modifiques esta secciÃ³n"
      ],
      "metadata": {
        "id": "RDHm4kReWNaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/weights\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P /content//weights"
      ],
      "metadata": {
        "id": "Nwx9LFSuP3DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = os.path.join(\"/content\", \"weights\", \"sam_vit_h_4b8939.pth\")\n",
        "print(checkpoint, \"; exist:\", os.path.isfile(checkpoint))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0cxWvIjQBbR",
        "outputId": "2876c2fe-472e-4cac-86b2-6ca450942b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/weights/sam_vit_h_4b8939.pth ; exist: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = \"vit_h\"\n",
        "\n",
        "sam = sam_model_registry[None](checkpoint=checkpoint).to(device=None)"
      ],
      "metadata": {
        "id": "-PN0_KW2AbOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sube cualquier imagen o imÃ¡genes aquÃ­ para trabajar**"
      ],
      "metadata": {
        "id": "YhRFoYINR68i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "image_paths = []\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  if not os.path.exists('uploaded_images'):\n",
        "    os.makedirs('uploaded_images')\n",
        "\n",
        "  path = os.path.join('uploaded_images', fn)\n",
        "  image_paths.append(path)\n",
        "\n",
        "  with open(path, 'wb') as f:\n",
        "    f.write(uploaded[fn])\n",
        "\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes and saved to {path}'.format(\n",
        "      name=fn, length=len(uploaded[fn]), path=path))\n",
        "\n",
        "# Guardamos los paths de cada image en image_path, descomenta la lÃ­nea de abajo para verlos\n",
        "#print(\"Saved image paths:\", image_paths)"
      ],
      "metadata": {
        "id": "PZnBeDoJiti3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# La posiciÃ³n del path depende del orden de subida de las imagenes a trabajar, si deseas cambiar la imagen,\n",
        "# modifica el Ã­ndice de la lista al path de la imagen a usar, no olvidar que los Ã­ndices empiezan hasta 0\n",
        "# y van hasta n-1 donde n es el nÃºmero de imÃ¡genes\n",
        "\n",
        "image_path = image_paths[0]\n",
        "src_image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(None, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image_rgb)\n",
        "plt.title('Source Image')\n",
        "plt.show() #VisualizaciÃ³n de la imagen seleccionada"
      ],
      "metadata": {
        "id": "PzTRLu6vioy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CreaciÃ³n de mÃ¡scaras y visualizaciÃ³n de SegmentaciÃ³n PanÃ³ptica**"
      ],
      "metadata": {
        "id": "b38RrgOncm3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear las mÃ¡scaras usando SAM a partir de la imagen RGB\n",
        "\n",
        "mask_generator = SamAutomaticMaskGenerator(None)\n",
        "src_image = cv2.imread(None)\n",
        "image_rgb = cv2.None(src_image, cv2.COLOR_BGR2RGB)\n",
        "sam_result = mask_generator.generate(None)"
      ],
      "metadata": {
        "id": "Pt6knNkigj-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "detections = sv.Detections.from_sam(sam_result=None)\n",
        "annotated_image = mask_annotator.annotate(scene=src_image.copy(), detections=detections)\n",
        "\n",
        "#VisualizaciÃ³n de las imÃ¡genes\n",
        "sv.plot_images_grid(\n",
        "    images=[None, None],\n",
        "    grid_size=(1, 2),\n",
        "    titles=['Source Image', 'Panoptic segmentation']\n",
        ")"
      ],
      "metadata": {
        "id": "pA5BXn6rglD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VisualizaciÃ³n de mÃ¡scaras de segmentaciÃ³n generadas por SAM**"
      ],
      "metadata": {
        "id": "oPwnXPIXdM6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "masks = [\n",
        "    mask['segmentation']\n",
        "    for None\n",
        "    in sorted(sam_result, key=lambda x: x['area'], reverse=True)\n",
        "]\n",
        "\n",
        "num_rows = (len(masks) + 7) // 8\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=None,\n",
        "    grid_size=(8, num_rows),\n",
        "    size=(16, 16)\n",
        ")"
      ],
      "metadata": {
        "id": "4QdD_YvagnDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#00FFFF'> **2. SegmentaciÃ³n semÃ¡ntica** </font>"
      ],
      "metadata": {
        "id": "DpxLrpBDzgCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Descargamos Mask2Former desde HuggingFace**"
      ],
      "metadata": {
        "id": "Vwmw-nAQHflx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#No modifiques esta secciÃ³n"
      ],
      "metadata": {
        "id": "elGMQeHjZrKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-base-coco-panoptic\")\n",
        "model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-base-coco-panoptic\")"
      ],
      "metadata": {
        "id": "WGxIE9sNgtwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Algunos labels del pre-entreno para buscar imÃ¡genes relacionadas a estos\n",
        "\n",
        "config = model.config\n",
        "id2label = config.id2label\n",
        "\n",
        "for id, label in list(id2label.items())[:10]:\n",
        "  print(f\"ID: {id}, Label: {label}\")"
      ],
      "metadata": {
        "id": "VdgnM26YgsVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sube cualquier imagen o imÃ¡genes aquÃ­ para trabajar**"
      ],
      "metadata": {
        "id": "wlPhtVp91Yux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "image_paths = []\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  if not os.path.exists('uploaded_images'):\n",
        "    os.makedirs('uploaded_images')\n",
        "\n",
        "  path = os.path.join('uploaded_images', fn)\n",
        "  image_paths.append(path)\n",
        "\n",
        "  with open(path, 'wb') as f:\n",
        "    f.write(uploaded[fn])\n",
        "\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes and saved to {path}'.format(\n",
        "      name=fn, length=len(uploaded[fn]), path=path))\n",
        "\n",
        "# Guardamos los paths de cada image en image_path, descomenta la lÃ­nea de abajo para verlos\n",
        "#print(\"Saved image paths:\", image_paths)"
      ],
      "metadata": {
        "id": "ybwz7N-kgvWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# La posiciÃ³n del path depende del orden de subida de las imagenes a trabajar, si deseas cambiar la imagen,\n",
        "# modifica el Ã­ndice de la lista al path de la imagen a usar, no olvidar que los Ã­ndices empiezan hasta 0\n",
        "# y van hasta n-1 donde n es el nÃºmero de imÃ¡genes\n",
        "\n",
        "image = image_paths[0]\n",
        "src_image = Image.open(image)\n",
        "plt.imshow(src_image)\n",
        "plt.title('Source Image')\n",
        "plt.show() #VisualizaciÃ³n de la imagen seleccionada"
      ],
      "metadata": {
        "id": "czVfNLxWh8-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Obtenemos las mÃ¡scaras de segmentaciÃ³n de Mask2Former**"
      ],
      "metadata": {
        "id": "urb7kLJaIy45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(images=None, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "d-aPdbVN1lU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(**None)"
      ],
      "metadata": {
        "id": "gWngDVhI2bo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_map = processor.post_process_semantic_segmentation(None, target_sizes=[None.size[::-1]])[0]\n",
        "print(predicted_map.shape)"
      ],
      "metadata": {
        "id": "xzZ6ke02ixIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_palette = [list(np.random.choice(range(256), size=3)) for _ in range(len(model.config.id2label))]\n",
        "print(color_palette)"
      ],
      "metadata": {
        "id": "DeHAKlA4iwQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VisualizaciÃ³n de SegmentaciÃ³n SemÃ¡ntica**"
      ],
      "metadata": {
        "id": "Rd1-NzSaKh9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seg = None # Cambio de nombre de una variable anterior\n",
        "color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8)\n",
        "palette = np.array(color_palette)\n",
        "for label, color in enumerate(palette):\n",
        "    color_seg[seg == label, :] = color\n",
        "# Convert to BGR\n",
        "color_seg = color_seg[..., ::-1]\n",
        "\n",
        "img = np.array(None)\n",
        "color_seg_resized = cv2.resize(color_seg, (img.shape[1], img.shape[0]))\n",
        "\n",
        "# Imagen y mÃ¡scara (NO modificar ğŸ™ğŸ¼)\n",
        "img = img * 0.5 + color_seg_resized * 0.5\n",
        "img = img.astype(np.uint8)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 8))\n",
        "\n",
        "#VisualizaciÃ³n de las imÃ¡genes\n",
        "axes[0].imshow(None)\n",
        "axes[0].set_title('Source Image')\n",
        "axes[1].imshow(None)\n",
        "axes[1].set_title('Semantic Segmentation')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8gvVqWWli-nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#00FFFF'> **3. SegmentaciÃ³n de instancias** </font>"
      ],
      "metadata": {
        "id": "8EK6cY_f5evv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sube cualquier imagen o imÃ¡genes aquÃ­ para trabajar**"
      ],
      "metadata": {
        "id": "VrhbcV_OSMIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "image_paths = []\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  if not os.path.exists('uploaded_images'):\n",
        "    os.makedirs('uploaded_images')\n",
        "\n",
        "  path = os.path.join('uploaded_images', fn)\n",
        "  image_paths.append(path)\n",
        "\n",
        "  with open(path, 'wb') as f:\n",
        "    f.write(uploaded[fn])\n",
        "\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes and saved to {path}'.format(\n",
        "      name=fn, length=len(uploaded[fn]), path=path))\n",
        "\n",
        "# Guardamos los paths de cada image en image_path, descomenta la lÃ­nea de abajo para verlos\n",
        "#print(\"Saved image paths:\", image_paths)"
      ],
      "metadata": {
        "id": "2LIFmZBQjCtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# La posiciÃ³n del path depende del orden de subida de las imagenes a trabajar, si deseas cambiar la imagen,\n",
        "# modifica el Ã­ndice de la lista al path de la imagen a usar, no olvidar que los Ã­ndices empiezan hasta 0\n",
        "# y van hasta n-1 donde n es el nÃºmero de imÃ¡genes\n",
        "\n",
        "image = image_paths[0]\n",
        "src_image = Image.open(image)\n",
        "plt.imshow(src_image)\n",
        "plt.title('Source Image')\n",
        "plt.show() #VisualizaciÃ³n de la imagen seleccionada"
      ],
      "metadata": {
        "id": "77oajJ0xjD4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Obtenemos las mÃ¡scaras de segmentaciÃ³n de Mask2Former**"
      ],
      "metadata": {
        "id": "KuLV3Q3fSUQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(images=src_image, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "nsdp1_9d9Be2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "NAtN9-2x9Be3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = processor.post_process_instance_segmentation(None, target_sizes=[None.size[::-1]], threshold=0.9)[0]\n",
        "print(results.keys())"
      ],
      "metadata": {
        "id": "-SBlFTUXjFsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ObtenciÃ³n de los IDs de las mÃ¡scaras para revisarlas de forma individual\n",
        "\n",
        "segment_to_label = {segment['id']: segment['label_id'] for segment in results[\"segments_info\"]}\n",
        "\n",
        "def get_available_segment_ids(results):\n",
        "\n",
        "    segmentation = results['segmentation'].numpy()\n",
        "    unique_ids = np.unique(segmentation)\n",
        "\n",
        "    available_ids = [id for id in unique_ids]\n",
        "\n",
        "    return available_ids\n",
        "\n",
        "available_ids = get_available_segment_ids(results)\n",
        "print(\"Available segment IDs:\", [id.item() for id in available_ids])"
      ],
      "metadata": {
        "id": "CHAQ4ioWjHLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VisualizaciÃ³n individual de mÃ¡scaras\n",
        "def get_mask(segment_id):\n",
        "  if segment_id in segment_to_label:\n",
        "    print(\"Visualizing mask for:\", model.config.id2label[None[None]])\n",
        "\n",
        "    mask = (None['segmentation'].None() == None)\n",
        "    visual_mask = (mask * 255).astype(np.uint8)\n",
        "    visual_mask = Image.fromarray(visual_mask)\n",
        "\n",
        "    plt.imshow(visual_mask)\n",
        "    plt.show()\n",
        "  else:\n",
        "    print(f\"Segment ID {segment_id} not found in segment_to_label. Skipping visualization.\")\n",
        "    return None\n",
        "\n",
        "get_mask(segment_id=0)"
      ],
      "metadata": {
        "id": "dYLE23NqjIQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VisualizaciÃ³n SegmentaciÃ³n de Instancias**"
      ],
      "metadata": {
        "id": "0y06VrW9VxzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_instance_segmentation(segmentation, segments_info):\n",
        "\n",
        "    fig, axes_arr = plt.subplots(1, 2, figsize=(10, 8)) # Create 2 subplots\n",
        "    axes_img, axes_seg = axes_arr\n",
        "\n",
        "    axes_img.imshow(None)\n",
        "    axes_img.set_title('Source Image')\n",
        "    axes_seg.imshow(None)\n",
        "    axes_seg.set_title('Instance Segmentation')\n",
        "\n",
        "    instance_colors = {}\n",
        "    for segment in None:\n",
        "        segment_id = None['id']\n",
        "        if segment_id not in instance_colors:\n",
        "            instance_colors[None] = [random.randint(0, 255) for _ in range(3)]\n",
        "\n",
        "    for segment in None:\n",
        "        segment_id = segment['id']\n",
        "        segment_label_id = segment['label_id']\n",
        "        segment_label = model.config.id2label[None]\n",
        "\n",
        "        mask = (segmentation.numpy() == None)\n",
        "\n",
        "        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for contour in contours:\n",
        "            axes_seg.plot(contour[:, 0, 0], contour[:, 0, 1], color=np.array(instance_colors[segment_id]) / 255, linewidth=0.5)\n",
        "\n",
        "        x, y = np.mean(contour, axis=0)[0]\n",
        "        axes_seg.text(x, y, segment_label, color='white', backgroundcolor=np.array(instance_colors[segment_id]) / 255, fontsize=8)\n",
        "\n",
        "    plt.show(/\n",
        "#VisualizaciÃ³n de las imÃ¡genes\n",
        "draw_instance_segmentation(**None)"
      ],
      "metadata": {
        "id": "CpfLFtMDjKEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#00FFFF'> **BibliografÃ­a** </font>\n",
        "\n",
        "Piotr Skalski. (Jan 22, 2024). How to Use the Segment Anything Model (SAM). Roboflow Blog: https://blog.roboflow.com/how-to-use-segment-anything-model-sam/\n",
        "\n",
        "Jacob Solawetz. (Apr 7, 2023). What is Segment Anything Model (SAM)? A Breakdown.. Roboflow Blog: https://blog.roboflow.com/segment-anything-breakdown/\n",
        "\n",
        "Rogge, N. (2025). Tutorials. Github Repository: https://github.com/NielsRogge/Transformers-Tutorials\n",
        "\n",
        "Cheng, B., Misra, I., Schwing, A. G., Kirillov, A., & Girdhar, R. (2022). Masked-attention Mask Transformer for Universal Image Segmentation. arXiv. https://arxiv.org/abs/2112.01527\n",
        "\n",
        "Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A. C., Lo, W.-Y., DollÃ¡r, P., & Girshick, R. (2023). Segment Anything. arXiv. https://arxiv.org/abs/2304.02643"
      ],
      "metadata": {
        "id": "3188tRNwY9mN"
      }
    }
  ]
}